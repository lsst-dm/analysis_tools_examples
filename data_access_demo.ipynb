{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "826655f1-f093-4491-9631-db3a3d872cbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:32:13.353992Z",
     "iopub.status.busy": "2023-04-19T04:32:13.353762Z",
     "iopub.status.idle": "2023-04-19T04:32:13.356535Z",
     "shell.execute_reply": "2023-04-19T04:32:13.356105Z",
     "shell.execute_reply.started": "2023-04-19T04:32:13.353976Z"
    }
   },
   "source": [
    "# Pre-bootcamp exercises: accessing data products via butler\n",
    "\n",
    "**Description:** Demonstrate how to generate science performance diagnostic plots and metrics with the [analysis_tools](https://github.com/lsst/analysis_tools) package using a small test dataset from HSC, [rc2_subset](https://github.com/lsst/rc2_subset).\n",
    "\n",
    "**Contact authors:** Keith Bechtol, Nate Lust\n",
    "\n",
    "**Last verified to run:** 2023-05-02\n",
    "\n",
    "**LSST Science Piplines version:** w_2023_17\n",
    "\n",
    "**Container Size:** Medium (or larger)\n",
    "\n",
    "**Location:** This notebook points to files on the S3DF cluster at the USDF. Update paths accordingly if you are running elsewhere.\n",
    "\n",
    "**Skills:** \n",
    "- Load source and object tables using the Butler.\n",
    "- Generate a science performance diagnostic plot and corresponding metric values interactively in a notebook and as part of a pipeline (simple pipeline executor). \n",
    "- Adjust the configuration used to produce these diagnostics. \n",
    "- Retrieve persisted plots and metrics with the Bulter. \n",
    "- Reconstitute input data products that were used to create plots and metrics for further investigation.\n",
    "\n",
    "\n",
    "For a quicker introduction, use an existing sandbox repo (prepared for this exercise) to bypass data reduction steps and go straight to data access via the Butler. If you want the full experience, run the data reduction steps in `process_rc2_subset.sh` and then point the Butler to your own repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfadd68-5fcc-4e45-8cc0-ac5553139592",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:41:39.575692Z",
     "iopub.status.busy": "2023-04-19T04:41:39.574983Z",
     "iopub.status.idle": "2023-04-19T04:41:39.577852Z",
     "shell.execute_reply": "2023-04-19T04:41:39.577435Z",
     "shell.execute_reply.started": "2023-04-19T04:41:39.575672Z"
    },
    "tags": []
   },
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18af6ebd-d52c-42b1-8ddf-0d8c5279ec8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6045ec69-4cfc-423e-9c58-aca6b96de7f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T01:26:13.350555Z",
     "iopub.status.busy": "2023-05-04T01:26:13.350110Z",
     "iopub.status.idle": "2023-05-04T01:26:13.353867Z",
     "shell.execute_reply": "2023-05-04T01:26:13.353352Z",
     "shell.execute_reply.started": "2023-05-04T01:26:13.350537Z"
    },
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Getting set up at USDF\n",
    "\n",
    "The USDF is hosted on the S3DF cluster at SLAC. This notebook has been verified to run on the S3DF cluster.\n",
    "\n",
    "See USDF documentation at\n",
    "* https://developer.lsst.io/usdf/lsst-login.html\n",
    "* https://developer.lsst.io/usdf/onboarding.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca88b668-c6ef-422b-aa05-399c0e42c3ad",
   "metadata": {},
   "source": [
    "### Processing rc2_subset\n",
    "\n",
    "[rc2_subset](https://github.com/lsst-dm/rc2_subset) is a small dataset with just enough Hyper Suprime-Cam (HSC) exposures to compute a set of meaningful science performance metrics.\n",
    "\n",
    "The LSST Science Pipelines [Getting Started tutorial](https://pipelines.lsst.io/#getting-started) provides a guided tour of data processing using rc2_subset as an example.\n",
    "\n",
    "For convenience, there is a shell script `process_rc2_subset.sh` in the same directory as this notebook that shows the commands to process rc2_subset on the USDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641a9b7f-b0f9-4d45-933d-5c123a51f9e8",
   "metadata": {},
   "source": [
    "### Setting up the analysis_tools package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53536611-c540-49fb-87db-9f45dc09bf98",
   "metadata": {},
   "source": [
    "Check the version of the stack you are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c5caf9-7177-4d59-9c69-0fce71bd0816",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!eups list -s | grep lsst_distrib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7712911a-48c9-499f-bb5c-e2c7d930c99b",
   "metadata": {},
   "source": [
    "The `analysis_tools` package was added to `lsst_distrib` in August 2022, and accordingly, if you have set up the LSST Stack version `w_2022_32` or later, then you should be able to import `analysis_tools` directly in the notebook.\n",
    "\n",
    "See the header for this notebook for the most recent verified Science Pipelines version for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63239e01-0499-4898-8101-fd01a3897acf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lsst.analysis.tools\n",
    "print(lsst.analysis.tools.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9e09fe-b7d4-41b2-9cad-5f61c4c14cff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T01:28:21.164082Z",
     "iopub.status.busy": "2023-05-04T01:28:21.163705Z",
     "iopub.status.idle": "2023-05-04T01:28:21.168877Z",
     "shell.execute_reply": "2023-05-04T01:28:21.168256Z",
     "shell.execute_reply.started": "2023-05-04T01:28:21.164065Z"
    },
    "tags": []
   },
   "source": [
    "**Additional background information:** If you are doing development on the `analysis_tools` package and want to test in a notebook, follow the guidance [here](https://nb.lsst.io/science-pipelines/development-tutorial.html). Brief version below (for work on the RSP at USDF):\n",
    "\n",
    "1. In the termal, clone the [analysis_tools](https://github.com/lsst/analysis_tools) repo and set up the package\n",
    "\n",
    "```\n",
    "source /opt/lsst/software/stack/loadLSST.bash\n",
    "setup lsst_distrib\n",
    "\n",
    "# Choose file location for your repo\n",
    "cd ~/repos/\n",
    "git clone https://github.com/lsst/analysis_tools.git\n",
    "cd analysis_tools\n",
    "setup -k -r .\n",
    "scons\n",
    "```\n",
    "\n",
    "2. Add the following line to `~/notebooks/.user_setups`\n",
    "\n",
    "```\n",
    "setup -k -r ~/repos/analysis_tools\n",
    "```\n",
    "\n",
    "Your local version of `analysis_tools` should now be accessible in a notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958b0c97-2bcd-42b9-a3de-083f4828c14e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea55f341-506c-4df0-a5a1-93810ded50d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.daf.butler as dafButler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38543d2d-5a45-4481-aebc-e67d2e8a239e",
   "metadata": {},
   "source": [
    "Point to a shared sandbox instance of the processed rc2_subset or point to your own instance. \n",
    "\n",
    "**Note:** For one of the sections later in the notebook that shows how to run analysis_tools as part of a pipeline, you need to point to your own processed instance of rc2_subset. That section can be skipped if you are pointing to the shared sandbox repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8502fc8-b7c0-42d5-b83e-2ceef4fa101c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Point to existing sandbox repo if you prefer to skip processing steps\n",
    "collections = ['u/bechtol']\n",
    "repo = '/sdf/group/rubin/user/bechtol/bootcamp_2023/rc2_subset/SMALL_HSC/'\n",
    "\n",
    "# User instance of the repo if you have processed rc2_subset yourself\n",
    "#collections = ['u/%s'%os.environ['USER']]\n",
    "#repo = '/sdf/group/rubin/user/%s/bootcamp_2023/rc2_subset/SMALL_HSC/'%(os.environ['USER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509e92e3-77e8-4fd9-bfab-4b1f764d70d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "butler = dafButler.Butler(repo, collections=collections)\n",
    "registry = butler.registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efe83a0-d105-4a49-8519-0ec861bf2b6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:34:52.356165Z",
     "iopub.status.busy": "2023-04-19T04:34:52.355921Z",
     "iopub.status.idle": "2023-04-19T04:34:52.358613Z",
     "shell.execute_reply": "2023-04-19T04:34:52.358183Z",
     "shell.execute_reply.started": "2023-04-19T04:34:52.356149Z"
    },
    "tags": []
   },
   "source": [
    "Check what dataset types are present in the collection. Note that the cell below will show _only the dataset types that are present in the specified collection_, not all of the possible dataset types that are known to the butler registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2522e7-35e1-4475-b503-e727bae939f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for datasetType in registry.queryDatasetTypes():\n",
    "    if registry.queryDatasets(datasetType, collections=collections).any(execute=False, exact=False):\n",
    "        print(datasetType)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6519bdbf-a9c7-4bb3-b9c1-c03e02177afa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Object tables\n",
    "\n",
    "The examples below use an object table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86f7ad8-a6e2-4b0a-b593-eef02f9d8211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "refs = sorted(registry.queryDatasets(\"objectTable_tract\"))\n",
    "print(len(refs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b4eb4b-9f19-4af2-b0d8-1d3a0ffed060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "refs[0].dataId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2b7687-a351-4422-93c9-7b73c9bcbb9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "objectTable = butler.get(refs[0])\n",
    "objectTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6fe2b7-3446-4ee9-8f6a-177ea5a9bfcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "objectTable.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1ea0e6-2412-4e8e-908c-57a77240e31d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T04:41:15.719044Z",
     "iopub.status.busy": "2023-04-19T04:41:15.718764Z",
     "iopub.status.idle": "2023-04-19T04:41:15.721677Z",
     "shell.execute_reply": "2023-04-19T04:41:15.721225Z",
     "shell.execute_reply.started": "2023-04-19T04:41:15.719027Z"
    }
   },
   "source": [
    "### Source tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7df9b9b-8985-4445-b5b3-e29190155a67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "refs = sorted(registry.queryDatasets(\"sourceTable_visit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88711a61-bd88-4fa0-b970-c002f04f19d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ref in refs: print(ref.dataId.full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8cc15d-a550-4d0f-9e88-80934df213f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sourceTable = butler.get(refs[-1])\n",
    "sourceTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eec9b9f-ac5a-4b0f-9c7f-449ac4e33bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sourceTable.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4e07fc-a438-47b0-aadb-2af33ec3d516",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run `analysis_tools` interactively\n",
    "\n",
    "Run an `AnalysisTool` interactively in a notebook by passing in-memory data inputs to create metrics and diagnostic plots.\n",
    "\n",
    "In this example, we compute PSF model size residuals relative to the observed PSF size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8b30ae-d864-42d9-9bb1-4866b7d25d81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lsst.analysis.tools.atools import ShapeSizeFractionalDiff\n",
    "from lsst.analysis.tools.interfaces._task import _StandinPlotInfo\n",
    "from lsst.analysis.tools.interfaces._actions import NoPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e103cb45-932c-45b7-a39b-b921f12a0da5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "atool = ShapeSizeFractionalDiff()\n",
    "atool.produce.plot.addSummaryPlot = False\n",
    "\n",
    "# Do not produce plot; only metric values\n",
    "#atool.produce.plot = NoPlot() \n",
    "\n",
    "# This helps simplify some of the configuration\n",
    "# by ensuring that appropriate keys are set to \n",
    "# load columns that are needed in later steps. \n",
    "# This happens automatically when an AnalysisTool \n",
    "# is used as a single unit.\n",
    "atool.populatePrepFromProcess() # Needed to run "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89e188f-d418-46f4-8bfb-81cc89012662",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T05:46:38.219181Z",
     "iopub.status.busy": "2023-05-03T05:46:38.218965Z",
     "iopub.status.idle": "2023-05-03T05:46:38.222496Z",
     "shell.execute_reply": "2023-05-03T05:46:38.221961Z",
     "shell.execute_reply.started": "2023-05-03T05:46:38.219165Z"
    },
    "tags": []
   },
   "source": [
    "Notice that the returned metric values match summary statistics displayed on the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a2791-9303-4520-a3f9-18547dff5da2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = atool(objectTable, band='i', skymap=None, plotInfo=_StandinPlotInfo())\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1909412c-2c20-4ab4-bd44-d60533313b43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T01:33:22.746626Z",
     "iopub.status.busy": "2023-05-04T01:33:22.746379Z",
     "iopub.status.idle": "2023-05-04T01:33:22.749197Z",
     "shell.execute_reply": "2023-05-04T01:33:22.748767Z",
     "shell.execute_reply.started": "2023-05-04T01:33:22.746610Z"
    },
    "tags": []
   },
   "source": [
    "## ConfigurableActions are the atomic bits of `analysis_tools`\n",
    "\n",
    "We introduce core concepts of the `analysis_tools` package, starting with the idea of [ConfigurableAction](https://pipelines.lsst.io/v/weekly/modules/lsst.pex.config/overview.html#specialized-config-subclasses)s, or actions for short."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0962a7d-4ef8-4764-87bb-14fb4b736d86",
   "metadata": {},
   "source": [
    "### Terminology\n",
    "\n",
    "Data Types (many of the [actions in analysis_tools](https://github.com/lsst/analysis_tools/tree/main/python/lsst/analysis/tools/actions) are grouped according to the resultant data type)\n",
    "* `Scalar`: Something that is number like (int, float, numpy.float32 etc.)\n",
    "* `Vector`: Something that is ndarray like\n",
    "* `KeyedData`: Anything that is indexed by a string that can return a Vector, or Scalar\n",
    "\n",
    "Analysis Structures\n",
    "* `ConfigurableAction`: generic interface for function-like objects (actions) that have state which can be set during configuration\n",
    "* `AnalysisAction`: A ConfigurableAction subclass that is specialized for actions that function in analysis contexts\n",
    "* `AnalysisTool`: A top level \"container\" of multiple AnalysisActions which performs one type of analysis\n",
    "\n",
    "We dive into the later two in more detail below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca962680-ff78-4782-a373-f121c8a97b34",
   "metadata": {},
   "source": [
    "### Using AnalysisActions\n",
    "\n",
    "- Configurable `AnalysisActions` are the atomic bits of `analysis_tools`. They can be combined together to make more complex actions, or used as part of an AnalysisTool\n",
    "- We show some examples of using configurable actions like standalone functions to provide intution for how configurable actions work.\n",
    "- Show examples with KeyedDataActions, VectorActions (including selectors), and ScalarActions\n",
    "- Show examples of configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a8dbc4-be1e-4f1a-92fe-03b289ae361b",
   "metadata": {},
   "source": [
    "Let's use actions to compute the measured PSF size for a set of stars from an object catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35c8e85-b8b3-4cd1-9d3f-08791afc01e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lsst.analysis.tools.actions.vector import CalcShapeSize, MagColumnNanoJansky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bba4288-5612-4add-8c90-6134a814da02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sizeCalculator = CalcShapeSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3f4c5a-178e-461c-a123-37c73d3166e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspect the configuration of this object.\n",
    "pprint(sizeCalculator.toDict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529f9254-c983-4c15-889f-e37ae3959d69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspect the required input schema, notice that we will need to provide the band information\n",
    "sizeCalculator.getInputSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcac39ad-74a3-4aae-b183-58158569cbb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "size = sizeCalculator(objectTable, band='i')\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4162b9cc-3b9c-404b-94d3-d46ffb443989",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Another example, this time to convert fluxes to magnitudes\n",
    "mag = MagColumnNanoJansky(vectorKey='{band}_psfFlux')(objectTable, band='i')\n",
    "\n",
    "# Notice that the line above is equiavalent to the following\n",
    "mag_alternate = MagColumnNanoJansky(vectorKey='i_psfFlux')(objectTable)\n",
    "\n",
    "assert np.allclose(mag, mag_alternate, equal_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c22da3d-56af-40e8-ae23-26ed4c50cb5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(mag, size, s=1)\n",
    "plt.xlim(17.5, 30.)\n",
    "plt.ylim(0, 5)\n",
    "plt.xlabel('mag')\n",
    "plt.ylabel('size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3812c7a4-7286-4b79-aa99-78597f71ff48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T01:38:05.230530Z",
     "iopub.status.busy": "2023-05-04T01:38:05.230271Z",
     "iopub.status.idle": "2023-05-04T01:38:05.233651Z",
     "shell.execute_reply": "2023-05-04T01:38:05.233123Z",
     "shell.execute_reply.started": "2023-05-04T01:38:05.230511Z"
    },
    "tags": []
   },
   "source": [
    "Let's remake that simple plot now selecting only the stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d119d2cc-546b-4ef7-a870-ec815ee3e0ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lsst.analysis.tools.actions.vector import StarSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931d898f-3187-4c5f-a51a-1f19c31315bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "star_selection = StarSelector()(objectTable, band='i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3fb2e0-6ce3-411a-9ba5-8c3646c38693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(mag[star_selection], size.values[star_selection], s=1)\n",
    "plt.xlim(17.5, 30.)\n",
    "plt.ylim(0, 5)\n",
    "plt.xlabel('mag')\n",
    "plt.ylabel('size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486e2060-3d75-4b9f-af13-6938b3e1ce8e",
   "metadata": {},
   "source": [
    "We can chain together `AnalysisAction`s, as in the following example that produces an equivalent plot. The `analysis_tools` package frequently uses this approach of chaining together `AnalysisAction`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c5fe7-421b-40af-8821-fb85f3d2c018",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lsst.analysis.tools.actions.vector import DownselectVector\n",
    "from lsst.analysis.tools.actions.keyedData import AddComputedVector\n",
    "\n",
    "band = \"i\"\n",
    "objectTableDemo = AddComputedVector(action=CalcShapeSize(), keyName=\"size\")(objectTable, band=band)\n",
    "\n",
    "# Note type(objectTable) is now a python dictionary instead of a pandas table, but since both\n",
    "# \"quack\" like KeyedData so they can be used interchangably\n",
    "\n",
    "objectTableDemo = AddComputedVector(\n",
    "    action=MagColumnNanoJansky(vectorKey='{band}_psfFlux'),\n",
    "    keyName=\"mag\"\n",
    ")(objectTableDemo, band=band)\n",
    "\n",
    "size = DownselectVector(vectorKey=\"size\", selector=StarSelector())(objectTableDemo, band=band)\n",
    "mag = DownselectVector(vectorKey=\"mag\", selector=StarSelector())(objectTableDemo, band=band)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(mag, size, s=1)\n",
    "plt.xlim(17.5, 30.)\n",
    "plt.ylim(0, 5)\n",
    "plt.xlabel('mag')\n",
    "plt.ylabel('size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e072acd2-7460-4912-8eee-d1adeadbe9e4",
   "metadata": {},
   "source": [
    "### Actions as a generic interface for data\n",
    "Actions are not restricted to tables or products loaded from the butler, `KeyedData` could also be things like dictionaries of numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f9865c-9c9e-4e68-9840-e63f4fd5431b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lsst.analysis.tools.actions\n",
    "dir(lsst.analysis.tools.actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c7a7b9-86c1-4fe5-94b3-e508aabc6e31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lsst.analysis.tools.actions.scalar import StdevAction\n",
    "\n",
    "# create some KeyedData\n",
    "data = {\"randomData\": np.random.normal(0, 3, 10000)}\n",
    "\n",
    "# initialize an action, setting it to use the key set above\n",
    "action = StdevAction(vectorKey=\"randomData\")\n",
    "\n",
    "#plt.figure()\n",
    "#plt.hist(data[\"randomData\"], bins=100, density=True)\n",
    "\n",
    "# Run the action and print the results\n",
    "print(f\"The standard deviation is {action(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d7771c-1d12-42f5-b439-273fce21683f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T05:19:13.011552Z",
     "iopub.status.busy": "2023-05-04T05:19:13.010913Z",
     "iopub.status.idle": "2023-05-04T05:19:13.013826Z",
     "shell.execute_reply": "2023-05-04T05:19:13.013369Z",
     "shell.execute_reply.started": "2023-05-04T05:19:13.011530Z"
    },
    "tags": []
   },
   "source": [
    "### Create a new action\n",
    "\n",
    "In the example below, we define a new VectorAction to multiply a vector by a scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ee1f7b-e2b3-4c1d-b5c8-a0d409dbeff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lsst.analysis.tools import VectorAction, KeyedData, KeyedDataSchema, Vector\n",
    "from lsst.pex.config import Field\n",
    "#rom lsstinterfaces import KeyedData, KeyedDataSchema\n",
    "\n",
    "class MultiplyByScalar(VectorAction):\n",
    "    \"\"\"Multiply vector by a scalar value\"\"\"\n",
    "\n",
    "    vectorKey = Field[str](doc=\"Key of vector which should be loaded\")\n",
    "    factor = Field[float](doc=\"Multiplicative factor\", default=1.)\n",
    "\n",
    "    def getInputSchema(self) -> KeyedDataSchema:\n",
    "        return ((self.vectorKey, Vector),)\n",
    "\n",
    "    def __call__(self, data: KeyedData, **kwargs) -> Vector:\n",
    "        return np.array(self.factor * data[self.vectorKey.format(**kwargs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b822cc7-8e40-4538-be49-84078187fbe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "action = MultiplyByScalar(vectorKey=\"randomData\", factor=2.)\n",
    "results = action(data)\n",
    "assert np.allclose(results, 2. * data['randomData'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166efc57-922d-41bf-a219-398717d1f576",
   "metadata": {},
   "source": [
    "### Three conceptual steps in an `AnalysisTool`: prep, process, produce\n",
    "\n",
    "As mentioned AnalysisTools can be thought of as executable containers of AnalysisActions. There are three different AnalysisActions, referred to as stages, named prep, process, and produce.\n",
    "* Prep: Responsible for any initial selection and filtering of data\n",
    "* Process: This is where any transformations and/or calculations are made\n",
    "* Produce: Generates final plot and/or metric objects\n",
    "\n",
    "The following examples will:\n",
    "* Walk through the three stages of running an analysis tool in sequential lines of code, passing the output of one step as input to the next step\n",
    "* Examine intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de63587-5da9-4263-975d-13d29597f963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prepResults = atool.prep(objectTable, band='i')\n",
    "processResults = atool.process(prepResults, band='i')\n",
    "produceResults = atool.produce(processResults, band='i', skymap=None, plotInfo=_StandinPlotInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c20ca1-0cdd-478a-82de-e62d6784ed5e",
   "metadata": {},
   "source": [
    "Inspect the intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58b7c8c-43db-4950-9f3d-92e57fdaddc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prepResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f8767-927b-480e-a53f-c27de41d8949",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processResults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa126f70-ba67-4d41-a86f-2534f66be0bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T01:51:31.319631Z",
     "iopub.status.busy": "2023-05-04T01:51:31.319043Z",
     "iopub.status.idle": "2023-05-04T01:51:31.321813Z",
     "shell.execute_reply": "2023-05-04T01:51:31.321442Z",
     "shell.execute_reply.started": "2023-05-04T01:51:31.319614Z"
    },
    "tags": []
   },
   "source": [
    "## Workflow examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c90e82-a6e3-4948-9deb-c22e9f17a8a2",
   "metadata": {},
   "source": [
    "### Running analysis_tools as part of a pipeline\n",
    "\n",
    "* **All examples in this notebook should use the simple pipeline executor** (here is how you do it in a notebook)\n",
    "* We have a PipelineTask for each data product. A task can run multiple AnalysisTools that each produce a set of plots or set of metrics and are subclasses of AnalysisPipelineTask.\n",
    "* Discuss an example yaml pipeline file (load the yaml)\n",
    "* Provide the command to run the pipeline\n",
    "* Show how to configure the pipeline, e.g., turning on or off different metrics and plots or changing other parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034775fb-763c-4c19-a414-8bbbff46167d",
   "metadata": {},
   "source": [
    "**WARNING:** If you are using your own processed instance of rc_subset, run the following cells to run analysis_tools as part of a pipeline from the notebook. If you are pointing to a shared sandbox instance of rc2_subset, skip the remaining cells in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e697f5-7b3f-4d2e-a160-6fb065823ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lsst.ctrl.mpexec import SimplePipelineExecutor\n",
    "from lsst.pipe.base import Pipeline\n",
    "\n",
    "# set up an output collection with your username\n",
    "analysisToolsCollection = \"u/%s/analysisToolsExample\"%os.environ['USER']\n",
    "\n",
    "# this can be skipped if you already have a read writable butler setup (above is read only)\n",
    "butlerRW = SimplePipelineExecutor.prep_butler(repo, inputs=collections, output=analysisToolsCollection)\n",
    "\n",
    "# load in the pipeline to run\n",
    "pipeline = Pipeline.from_uri(\"$ANALYSIS_TOOLS_DIR/pipelines/coaddQualityCore.yaml\")\n",
    "\n",
    "# override a configuration within a certain AnalysisTool\n",
    "#configKey = \"atools.shapeSizeFractionalDiff.prep.selectors.snSelector.threshold\"\n",
    "#pipeline.addConfigOverride(\"analyzeObjectTableCore\", configKey, 400)\n",
    "\n",
    "# Run only the PSF size residual tool\n",
    "pipeline.addConfigOverride(\"analyzeObjectTableCore\", \"atools\", None)\n",
    "pipeline.addConfigOverride(\"analyzeObjectTableCore\", \"atools.shapeSizeFractionalDiff\", ShapeSizeFractionalDiff)\n",
    "\n",
    "#bands = ['g', 'r', 'i', 'z']\n",
    "bands = ['i']\n",
    "pipeline.addConfigOverride(\"analyzeObjectTableCore\", \"bands\", bands)\n",
    "pipeline.addConfigOverride(\"catalogMatchTract\", \"bands\", bands)\n",
    "pipeline.addConfigOverride(\"refCatObjectTract\", \"bands\", bands)\n",
    "\n",
    "# restrict processing to the same dataId used above\n",
    "whereString = \"tract = 9813 AND skymap = 'hsc_rings_v1'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82652abd-f938-4a98-8f67-0eebe77324a6",
   "metadata": {},
   "source": [
    "Display the pipeline that is about to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0044cb7f-df8d-4c3f-8261-df46178f912e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65aa110-38a8-4c41-9386-14222517a2ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prevent the executor from dumping plots into the notebook\n",
    "backend_ =  mpl.get_backend() \n",
    "mpl.use(\"Agg\")\n",
    "\n",
    "executor = SimplePipelineExecutor.from_pipeline(pipeline, where=whereString, butler=butlerRW)\n",
    "quanta = executor.run(True)\n",
    "\n",
    "# Restore the ability for plots to be put into the notebook\n",
    "mpl.use(backend_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9009ec-38b0-4c67-954b-899974fd32f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Refresh our read-only butler to see the changes made. (It's generally a\n",
    "# good idea to work on read-only things)\n",
    "butler.registry.refresh()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb24d5d-13f9-4c37-9f75-969b49eef233",
   "metadata": {},
   "source": [
    "## Access persisted metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb1f09c-165b-41fa-8544-a2aaa44d5b6f",
   "metadata": {},
   "source": [
    "Specify the collection that holds the results of running analysis_tools. If you are pointing to your own instance of rc2_subset, you did this already above prior to running the pipeline and you can comment out the line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac51e0e-2ea4-48ea-881d-76f5bd5fbdc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Comment out the line below if you are pointing to your own instance of rc2_subset\n",
    "analysisToolsCollection = \"u/bechtol/analysisToolsExample\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c474ece0-6b8b-4e8c-989e-db23e23c8827",
   "metadata": {},
   "source": [
    "Check what dataset types exist in the new collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718585b6-757e-4de5-a3e1-ebfdc16e8164",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# See what datasets exist; there should now be objectTableCore_metrics\n",
    "for datasetType in registry.queryDatasetTypes():\n",
    "    if registry.queryDatasets(datasetType, collections=analysisToolsCollection).any(execute=False, exact=False):\n",
    "        print(datasetType)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e88923-cc4f-4cfc-93ea-7f89f5620236",
   "metadata": {},
   "source": [
    "Access the persisted metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a790bf8-a35b-44b0-8fa8-8640cc434506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the metric that was written\n",
    "refs = sorted(butler.registry.queryDatasets(\"objectTableCore_metrics\", collections=analysisToolsCollection))\n",
    "print(refs)\n",
    "dataId = refs[0].dataId\n",
    "objectTable_metrics = butler.get(\"objectTableCore_metrics\", dataId=refs[0].dataId, collections=analysisToolsCollection)\n",
    "pprint(objectTable_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1373184e-244f-4be7-ace0-9bee74833895",
   "metadata": {},
   "source": [
    "Also, we can see that a plot has been persisted, but there isn't a way to visualize the plot from the notebook. In the next section, we'll use the `reconstructor` to recreate the plot in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67690e31-e5d6-4013-944e-21c5a93e7b93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "refs = sorted(butler.registry.queryDatasets(\n",
    "    \"objectTableCore_i_shapeSizeFractionalDiff_ScatterPlotWithTwoHists\", \n",
    "    collections=analysisToolsCollection)\n",
    ")\n",
    "print(refs[0])\n",
    "\n",
    "# The following line will throw an error\n",
    "# plot = butler.get(\n",
    "#     \"objectTableCore_i_shapeSizeFractionalDiff_ScatterPlotWithTwoHists\",\n",
    "#     dataId=refs[0].dataId,\n",
    "#     collections=analysisToolsCollection\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c00f34-bef0-4f9b-be9a-b5d82974674f",
   "metadata": {},
   "source": [
    "### Reconstruct the inputs to an `AnalysisTool`\n",
    "\n",
    "Analysis(Tools/Actions) allow the exact state of `AnalysisTool`s to be saved into the Butler when a pipeline is run. This allows a user to 'reconstruct' things as they were when the tools were executed. This aids in debugging and deep diving into the data.\n",
    "\n",
    "Below is an example of reconstructing one of the tasks that was run in the Pipeline above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1569bb6f-6dd7-4619-969a-1d4f9dd0bd3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lsst.analysis.tools.tasks.reconstructor import reconstructAnalysisTools\n",
    "\n",
    "# Read in just one task\n",
    "label = \"analyzeObjectTableCore\"\n",
    "taskState, inputData = reconstructAnalysisTools(butler, \n",
    "                                                collection=analysisToolsCollection, \n",
    "                                                label=label, \n",
    "                                                dataId=dataId, \n",
    "                                                callback=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c96a9-d8a7-4a04-9461-8160779c3692",
   "metadata": {},
   "source": [
    "We have access to the exact configuration that was used to run the analysis tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc4d194-e979-4f5e-a7e7-7709c4b9a56c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pprint(taskState.toDict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba7df8d-39a6-4eb8-8658-bc62ea8e3b63",
   "metadata": {},
   "source": [
    "We also have access to the input data that were used to produce the diagnostics, in this case, the object table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2912a99c-b963-499c-a413-0dca8c869290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputData[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8598951-1c6c-4773-aab9-dddafbe1561b",
   "metadata": {},
   "source": [
    "Quick check to verify that the object table data are indeed the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c838cb-ca4e-4603-af90-3af2b5527774",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert np.allclose(inputData[\"data\"]['coord_ra'], objectTable['coord_ra'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e908a5e2-b9c8-4e48-b069-54ff1ecaac26",
   "metadata": {},
   "source": [
    "We can now reproduce diagnostic metrics and plots interactively in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6877c94-35a8-433e-b3b8-c51d48ad0f30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The following configuration won't be needed in the future\n",
    "taskState.atools.shapeSizeFractionalDiff.produce.plot.addSummaryPlot = False\n",
    "\n",
    "taskState.atools.shapeSizeFractionalDiff(\n",
    "    inputData['data'],\n",
    "    band='i',\n",
    "    skymap=None,\n",
    "    plotInfo=_StandinPlotInfo()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b0701d-8753-45dc-a786-5986cb834c82",
   "metadata": {},
   "source": [
    "Next, we change one of the configuration parameters to see how the results change. \n",
    "\n",
    "In this example, we raise the signal-to-noise threshold to 200. Notice that the metric values and plot change with this updated object selection criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ec74c4-429c-4d76-8b16-7859b283a8a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change some configuration to see the differences\n",
    "taskState.atools.shapeSizeFractionalDiff.prep.selectors.snSelector.threshold = 200\n",
    "taskState.atools.shapeSizeFractionalDiff(\n",
    "    inputData['data'],\n",
    "    band='i',\n",
    "    skymap=None,\n",
    "    plotInfo=_StandinPlotInfo()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a40cf10-9df9-472d-b656-fd99dba20c4a",
   "metadata": {},
   "source": [
    "As before, we can also step through the calculation to check intermediate steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687feae9-6996-449d-b7a7-b12ba71d2791",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prepResults = taskState.atools.shapeSizeFractionalDiff.prep(objectTable, band='i')\n",
    "processResults = taskState.atools.shapeSizeFractionalDiff.process(prepResults, band='i')\n",
    "produceResults = taskState.atools.shapeSizeFractionalDiff.produce(processResults, band='i', skymap=None, plotInfo=_StandinPlotInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5a688a-bb97-4ac3-87b1-a69ed2d5371f",
   "metadata": {},
   "source": [
    "## Create a new analysis tool\n",
    "\n",
    "Example `AnalysisTool`s can be found in the [atools](https://github.com/lsst/analysis_tools/tree/main/python/lsst/analysis/tools/atools) directory of the package.\n",
    "\n",
    "Now let's create our own `AnalysisTool`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a4ea7c-cc92-425f-89de-f85b9847c42a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lsst.analysis.tools import AnalysisTool\n",
    "from lsst.analysis.tools.actions.scalar import MedianAction, CountAction\n",
    "from lsst.analysis.tools.actions.vector import SnSelector\n",
    "\n",
    "\n",
    "class DemoTool(AnalysisTool):\n",
    "    #parameterizedBand: bool = False\n",
    "    \n",
    "    def setDefaults(self):\n",
    "        super().setDefaults()\n",
    "        \n",
    "        # select on high signal to noise obejcts\n",
    "        # add in a signal to noise selector\n",
    "        self.prep.selectors.snSelector = SnSelector()\n",
    "        \n",
    "        # set what key the selector should use when deciding SNR\n",
    "        self.prep.selectors.snSelector.fluxType = \"psfFlux\"\n",
    "        \n",
    "        # select what threshold value is desireable for the selector\n",
    "        self.prep.selectors.snSelector.threshold = 10\n",
    "        \n",
    "        # the final name in the qualification is used as a key to insert\n",
    "        # the calculation into KeyedData\n",
    "        self.process.calculateActions.median = MedianAction(vectorKey=\"psfFlux\")\n",
    "        self.process.calculateActions.count = CountAction(vectorKey=\"psfFlux\")\n",
    "        \n",
    "        # tell the metic what the units are for the quantity\n",
    "        self.produce.metric.units = {\"median\": \"Jy\",\n",
    "                                     \"count\": \"count\"}\n",
    "        \n",
    "        # Rename the quanity prior to producing the Metric\n",
    "        # (useful for resuable workflows that set a name toward the end of computation)\n",
    "        #self.produce.metric.newNames = {\"medianValueName\": \"DemoMetric\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc314fb-6312-49c5-b34e-de2641e0d109",
   "metadata": {},
   "source": [
    "Examine the configuration of our new tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ea7b18-81fe-4427-8f0f-813b8be89256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DemoTool().toDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bd6355-e71c-4548-82da-6a68d72a91a9",
   "metadata": {},
   "source": [
    "Make some synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea5ed3d-860c-4670-b509-241d20fc5b43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make some synthetic data\n",
    "size = 500\n",
    "flux = np.logspace(1., 4., size)\n",
    "fluxErr = np.sqrt(flux)\n",
    "flux += np.random.normal(0, np.sqrt(flux), size)\n",
    "data = {\"psfFlux\": flux, \"psfFluxErr\": fluxErr}\n",
    "\n",
    "plt.figure()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.scatter(data['psfFlux'], data['psfFluxErr'])\n",
    "plt.xlabel('psfFlux')\n",
    "plt.ylabel('psfFluxErr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78795035-d65b-4349-8311-95ca916f9479",
   "metadata": {},
   "source": [
    "Run the new analysis tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afd643a-97b2-4e46-9b8f-4ba74e3c82a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "demoTool = DemoTool()\n",
    "demoTool.populatePrepFromProcess()\n",
    "\n",
    "# We can configure as needed\n",
    "demoTool.prep.selectors.snSelector.threshold = 50\n",
    "\n",
    "demoTool(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a570e5ab-f6cb-4622-b40f-a5404b70ddc6",
   "metadata": {},
   "source": [
    "We can inspect intermediate stages of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76aea13-d00b-4da9-8ee0-73848cc39d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example: how many of the data points pass the SNR threshold?\n",
    "len(demoTool.prep(data)['psfFlux'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4b5ed1-20ae-4a34-af96-7fdb27811764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
