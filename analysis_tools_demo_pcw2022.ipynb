{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ea952a0-7d6b-4665-860f-941f23b98a90",
   "metadata": {},
   "source": [
    "# Analysis Tools Examples\n",
    "\n",
    "**Description:** Introduction to generating science performance diagnostic plots and metrics with the [analysis_tools](https://github.com/lsst/analysis_tools) package using a small test dataset from HSC.\n",
    "\n",
    "**Contact authors:** Nate Lust, Keith Bechtol\n",
    "\n",
    "**Last verified to run:** 2023-05-22\n",
    "\n",
    "**LSST Science Piplines version:** Weekly 2023_20\n",
    "\n",
    "**Container size:** medium\n",
    "\n",
    "**Targeted learning level:** intermediate\n",
    "\n",
    "**Skills:** \n",
    "* Generate a science performance diagnostic plot and corresponding metric values interactively in a notebook and as part of a pipeline (simple pipeline executor). \n",
    "* Adjust the configuration used to produce these diagnostics. \n",
    "* Retrieve persisted plots and metrics with the Bulter. \n",
    "* Reconstitute input data products that were used to create plots and metrics for further investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be12865f-39a5-4865-8bb2-7ab5de9a4217",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da54d3a9-860d-4216-bf7e-8149eeea939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2d20d-145d-4f6c-a2ef-163939882a6a",
   "metadata": {},
   "source": [
    "### Getting set up at USDF\n",
    "\n",
    "The USDF is hosted on the S3DF cluster at SLAC. This notebook has been verified to run on the S3DF cluster.\n",
    "\n",
    "See USDF documentation at\n",
    "* https://developer.lsst.io/usdf/lsst-login.html\n",
    "* https://developer.lsst.io/usdf/onboarding.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d2cbc4-c192-4ac3-a839-34c6b1ee8783",
   "metadata": {},
   "source": [
    "### Processing rc2_subset\n",
    "\n",
    "[rc2_subset](https://github.com/lsst-dm/rc2_subset) is a small dataset with just enough Hyper Suprime-Cam (HSC) exposures to compute a set of meaningful science performance metrics.\n",
    "\n",
    "The LSST Science Pipelines [Getting Started tutorial](https://pipelines.lsst.io/#getting-started) provides a guided tour of data processing using rc2_subset as an example.\n",
    "\n",
    "For convenience, there is a shell script `process_rc2_subset.sh` in the same directory as this notebook that shows the commands to process rc2_subset on the USDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cd1179-5ab4-493e-9eea-fea5182de600",
   "metadata": {},
   "source": [
    "### Setting up the analysis_tools package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049eb86c-8d4b-4526-9fa6-2160a3228fd9",
   "metadata": {},
   "source": [
    "Check the version of the stack you are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b868fc-f869-45fb-a01f-0ccf43b59dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!eups list -s | grep lsst_distrib\n",
    "!eups list -s | grep LOCAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f442c0f3-5702-4afd-85cd-3e2cdb70394e",
   "metadata": {},
   "source": [
    "The `analysis_tools` package was added to `lsst_distrib` in August 2022, and accordingly, if you have set up the LSST Stack version `w_2022_32` or later, then you should be able to import `analysis_tools` directly in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af82237-10d0-4693-9fd4-05ed8da480ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.analysis.tools\n",
    "print(lsst.analysis.tools.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe860cd-cbf6-4548-aed0-1cc3a7af3f5d",
   "metadata": {},
   "source": [
    "If you are doing development on the `analysis_tools` package and want to test in a notebook, follow the guidance [here](https://nb.lsst.io/science-pipelines/development-tutorial.html). Brief version below (for work on the RSP at USDF):\n",
    "\n",
    "1. In the termal, clone the [analysis_tools](https://github.com/lsst/analysis_tools) repo and set up the package\n",
    "\n",
    "```\n",
    "source /opt/lsst/software/stack/loadLSST.bash\n",
    "setup lsst_distrib\n",
    "\n",
    "# Choose file location for your repo\n",
    "cd ~/repos/\n",
    "git clone https://github.com/lsst/analysis_tools.git\n",
    "cd analysis_tools\n",
    "setup -k -r .\n",
    "scons\n",
    "```\n",
    "\n",
    "2. Add the following line to `~/notebooks/.user_setups`\n",
    "\n",
    "```\n",
    "setup -k -r ~/repos/analysis_tools\n",
    "```\n",
    "\n",
    "Your local version of `analysis_tools` should now be accessible in a notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e0410-c282-4ea3-93d1-8f5f4d717530",
   "metadata": {},
   "source": [
    "## Generating consistent metric values and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914442b8-d6e3-4ae4-84a6-e60c089bdde6",
   "metadata": {},
   "source": [
    "### Load data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1830eb9c-ca76-4d1f-b8a7-f59e97cd8167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.daf.butler import Butler\n",
    "\n",
    "#repo = \"/project/sandbox/bechtol/rc2_subset/SMALL_HSC\"\n",
    "repo = \"/fs/ddn/sdf/group/rubin/sandbox/bechtol/rc2_subset/SMALL_HSC/\"\n",
    "collection = \"u/bechtol/step3\"\n",
    "\n",
    "#repo = \"~/repos_lsst/rc2_subset/SMALL_HSC\"\n",
    "#collection = \"u/natelust/step3\"\n",
    "\n",
    "butler = Butler(repo, collections=[collection])\n",
    "registry = butler.registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5a6b82-0dc0-4bcd-92c7-a71fe306ca66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the available dataset types\n",
    "for d in sorted(registry.queryDatasetTypes()): print(d.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d774e3b3-3ef8-4e75-9018-75f664f6c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There should be one objectTable_tract catalog available\n",
    "sorted(registry.queryDatasets(\"objectTable_tract\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f1318-8fb9-45a3-9ed4-9bfeae294f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataId = {\"tract\": 9813, \"instrument\": \"hsc\"}\n",
    "tableName = \"objectTable_tract\"\n",
    "objectTable = butler.get(tableName, dataId=dataId)\n",
    "objectTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe3f274-5ca8-44ca-96d5-0c910a8e028a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show the column names\n",
    "objectTable.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ac9ee-f2c4-43d0-bbd0-364f705bd666",
   "metadata": {},
   "source": [
    "### Generate a metric and plot from a single tool\n",
    "\n",
    "* Instantiate a butler, load some data\n",
    "* Pass loaded data to an `AnalysisTool` to make metrics and plots\n",
    "\n",
    "In this example, we compute PSF model size residuals relative to the observed PSF size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ce7f05-1a27-4cdd-94c3-f9357c0d2dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.analysis.tools.atools import ShapeSizeFractionalDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621bc570-aafe-4fd9-a58a-3326aa2e646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = ShapeSizeFractionalMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888e053c-71ef-427c-b1b6-980c2214983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = ShapeSizeFractionalDiff()\n",
    "# An important step to ensure that the \"prep\" stage returns masked\n",
    "# vectors for all relevant keys from the table. This is normally\n",
    "# done automatically in pipelines.\n",
    "action.populatePrepFromProcess()\n",
    "action.process.calculateActions.stars.highSNSelector.threshold = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f319b48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional setup for the metric\n",
    "plotInfo = dataId.copy()\n",
    "plotInfo.update({\n",
    "    'bands': 'grizy',\n",
    "    'run': 'rc2',\n",
    "    'tableName': tableName,\n",
    "})\n",
    "skymap = butler.get('skyMap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888e053c-71ef-427c-b1b6-980c2214983f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Returns a dict, the first item is the plot which is shown below\n",
    "results = action(objectTable, band='i', skymap=skymap, plotInfo=plotInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d2b4a-377c-45c7-b9c2-299e03e88a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print metric values\n",
    "from lsst.verify.measurement import Measurement\n",
    "\n",
    "for key, value in results.items():\n",
    "    print(value if isinstance(value, Measurement) else f'{key}: {type(value)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ffea76-10ee-49b8-a468-9499e5358f9b",
   "metadata": {},
   "source": [
    "## How it works "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748991dd",
   "metadata": {},
   "source": [
    "### Terminology\n",
    "\n",
    "Data Types\n",
    "* Scalar - Something that is number like (int, float, numpy.float32 etc.)\n",
    "* Vector - Something that is ndarray like\n",
    "* KeyedData - Anything that is indexed by a string that can return a Vector, or Scalar\n",
    "\n",
    "Analysis Structures\n",
    "* ConfigurableAction - generic interface for function like objects (actions) that have state which can be set during configuration\n",
    "* AnalysisAction - A ConfigurableAction subclass that is specialized for actions that function in analysis contexts\n",
    "* AnalysisTool - A top level \"container\" of multiple AnalysisActions which performs one type of analysis\n",
    "\n",
    "Below we dive into the later two in more detail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b669978-bb2f-4564-98a5-73bb88a658a7",
   "metadata": {},
   "source": [
    "### Using AnalysisActions\n",
    "\n",
    "* These are the atomic bits of analysis_tools; They can be combined together to make more complex actions, or used as part of an AnalysisTool\n",
    "* Show some examples of using configurable actions like standalone functions. This is intended to provide users with more intution about how configurable actions work.\n",
    "* Examples with KeyedDataActions, VectorActions (including selectors), and ScalarActions\n",
    "* Show examples of configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d995033-8aca-47f2-9dc4-d2a0c23c440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.analysis.tools.actions.vector import CalcShapeSize, ConvertFluxToMag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f486b93-0a8a-43af-b232-ebd4d83bc150",
   "metadata": {},
   "source": [
    "Let's create an example AnalysisAction to compute the measured PSF size for a set of stars from an object catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa6d3c-f3c6-49ab-aac3-e236086b7dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeCalculator = CalcShapeSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5ca9ca-4b41-4d3a-9227-12493db36eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the configuration of this object.\n",
    "pprint(sizeCalculator.toDict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4af1d1-6cfd-4709-80c5-9b7d057f1667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the required input schema, notice that we will need to provide the band information\n",
    "sizeCalculator.getInputSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d5f028-6ee5-4188-a82d-9e00dfb12ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = sizeCalculator(objectTable, band='i')\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd32b465-6ec3-4962-a813-a8b201991d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another example, this time to convert fluxes to magnitudes\n",
    "mag = ConvertFluxToMag(vectorKey='{band}_psfFlux')(objectTable, band='i')\n",
    "\n",
    "# Notice that the line above is equiavalent to the following\n",
    "mag_alternate = ConvertFluxToMag(vectorKey='i_psfFlux')(objectTable)\n",
    "\n",
    "assert np.allclose(mag, mag_alternate, equal_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e0a34e-7c67-4115-b653-ebf735af56c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(mag, size, s=1)\n",
    "plt.xlim(17.5, 30.)\n",
    "plt.ylim(0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64c079f-c44b-43f6-bfa9-bd856a2bc752",
   "metadata": {},
   "source": [
    "Let's remake that simple plot now selecting only the stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcd3fa1-0151-4c7f-9c38-eaec5ad50143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.analysis.tools.actions.vector import StarSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c67d36d-b585-483d-88a8-103f4338d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_selection = StarSelector()(objectTable, band='i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a903edc8-fcf1-4d3a-ba60-e26068324460",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(mag[star_selection], size.values[star_selection], s=1)\n",
    "plt.xlim(17.5, 30.)\n",
    "plt.ylim(0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455c065d-1d3e-4b72-864a-8ba1018fa2de",
   "metadata": {},
   "source": [
    "We can also chain together AnalysisActions, as in the following example that produces an equivalent plot. The `analysis_tools` package frequently uses this approach of chaining together AnalysisActions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b668fb91-9902-4123-bb6b-137c6ab5ac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.analysis.tools.actions.vector import DownselectVector\n",
    "from lsst.analysis.tools.actions.keyedData import AddComputedVector\n",
    "\n",
    "band = \"i\"\n",
    "objectTable = AddComputedVector(action=CalcShapeSize(), keyName=\"size\")(objectTable, band=band)\n",
    "\n",
    "# Note type(objectTable) is now a python dictionary instead of a pandas table, but since both\n",
    "# \"quack\" like KeyedData so they can be used interchangably\n",
    "\n",
    "objectTable = AddComputedVector(\n",
    "    action=ConvertFluxToMag(vectorKey='{band}_psfFlux'),\n",
    "    keyName=\"mag\"\n",
    ")(objectTable, band=band)\n",
    "\n",
    "size = DownselectVector(vectorKey=\"size\", selector=StarSelector())(objectTable, band=band)\n",
    "mag = DownselectVector(vectorKey=\"mag\", selector=StarSelector())(objectTable, band=band)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(mag, size, s=1)\n",
    "plt.xlim(17.5, 30.)\n",
    "plt.ylim(0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f820d51f",
   "metadata": {},
   "source": [
    "### Generic interface for data\n",
    "Actions are not restricted to tables or products loaded from the butler, KeyedData could also be things like dictionaries of numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061fc0e9-3a87-4d20-9687-a5ba67fe7fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.analysis.tools.actions\n",
    "dir(lsst.analysis.tools.actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a19863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.analysis.tools.actions.scalar import StdevAction\n",
    "\n",
    "# create some KeyedData\n",
    "data = {\"randomData\": np.random.normal(0, 3, 100)}\n",
    "\n",
    "# initialize an action, setting it to use the key set above\n",
    "action = StdevAction(vectorKey=\"randomData\")\n",
    "\n",
    "# Run the action and print the results\n",
    "print(f\"The standard deviation is {action(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b87375-73df-4fe5-8808-5eccfdead3f6",
   "metadata": {},
   "source": [
    "### Three conceptual steps in an `AnalysisTool`: prep, process, produce\n",
    "\n",
    "As mentioned AnalysisTools can be thought of as executable containers of AnalysisActions. There are three different AnalysisActions, referred to as stages, named prep, process, and produce.\n",
    "* Prep - Responsible for any initial selection and filtering of data\n",
    "* Process - This is where any transformations or derived data should be computed\n",
    "* Produce - Generates final plot or metric objects\n",
    "\n",
    "The following examples will:\n",
    "* Walk through the three stages of running an analysis tool in sequential lines of code, passing the output of one step as input to the next step\n",
    "* Examine intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab2b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new instance of the AnalysisPlot we used earlier\n",
    "action = ShapeSizeFractionalDiff()\n",
    "\n",
    "action.populatePrepFromProcess()\n",
    "\n",
    "# Run the action by stepping through each stage\n",
    "stage1 = action.prep(objectTable, band='i')\n",
    "print(stage1.keys())\n",
    "stage2 = action.process(stage1, band='i')\n",
    "print(stage2.keys())\n",
    "figure = action.produce(stage2, band='i', skymap=skymap, plotInfo=plotInfo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee2cb51-b412-4a13-9829-cfd267f8ef7e",
   "metadata": {},
   "source": [
    "## Workflow examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c55816-f242-4c8e-81f4-8bdafedcd29e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Running analysis_tools as part of a pipeline\n",
    "\n",
    "* **All examples in this notebook should use the simple pipeline executor** (here is how you do it in a notebook)\n",
    "* We have a PipelineTask for each data product. A task can run multiple AnalysisTools that each produce a set of plots or set of metrics and are subclasses of AnalysisPipelineTask.\n",
    "* Discuss an example yaml pipeline file (load the yaml)\n",
    "* Provide the command to run the pipeline\n",
    "* Show how to configure the pipeline, e.g., turning on or off different metrics and plots or changing other parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f41f426",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "This is a copy of the coaddQualityCore pipeline in analysis_tools, reproduced here for reference\n",
    "```\n",
    "description: |\n",
    "  Tier1 plots and metrics to assess coadd quality\n",
    "tasks:\n",
    "  analyzeObjectTableCore:\n",
    "    class: lsst.analysis.tools.tasks.ObjectTableTractAnalysisTask\n",
    "    config:\n",
    "      connections.outputName: objectTableCore\n",
    "      plots.shapeSizeFractionalDiffScatter: ShapeSizeFractionalDiffScatterPlot\n",
    "      metrics.shapeSizeFractionalMetric: ShapeSizeFractionalMetric\n",
    "      plots.e1DiffScatter: E1DiffScatterPlot\n",
    "      metrics.e1DiffScatterMetric: E1DiffMetric\n",
    "      plots.e2DiffScatter: E2DiffScatterPlot\n",
    "      metrics.e2DiffScatterMetric: E2DiffMetric\n",
    "      metrics.skyFluxStatisticMetric: SkyFluxStatisticMetric\n",
    "      metrics.skyFluxStatisticMetric.applyContext: CoaddContext\n",
    "      python: |\n",
    "        from lsst.analysis.tools.analysisPlots import *\n",
    "        from lsst.analysis.tools.analysisMetrics import *\n",
    "        from lsst.analysis.tools.contexts import *\n",
    "  catalogMatchTract:\n",
    "    class: lsst.analysis.tools.tasks.catalogMatch.CatalogMatchTask\n",
    "    config:\n",
    "      bands: ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "  refCatObjectTract:\n",
    "    class: lsst.analysis.tools.tasks.refCatObjectAnalysis.RefCatObjectAnalysisTask\n",
    "    config:\n",
    "      bands: ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "      ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b465db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lsst.ctrl.mpexec import SimplePipelineExecutor\n",
    "from lsst.pipe.base import Pipeline\n",
    "\n",
    "# set up an output collection with your username\n",
    "#outputCollection = \"u/nate2/analysisToolsExample\"\n",
    "outputCollection = \"u/bechtol/analysisToolsExample\"\n",
    "\n",
    "# this can be skipped if you already have a read writable butler setup (above is read only)\n",
    "butlerRW = SimplePipelineExecutor.prep_butler(repo, inputs=[collection], output=outputCollection)\n",
    "\n",
    "# load in the pipeline to run\n",
    "pipeline = Pipeline.from_uri(\"$ANALYSIS_TOOLS_DIR/pipelines/coaddQualityCore.yaml\")\n",
    "\n",
    "# override a configuration within a certain AnalysisTool\n",
    "configKey = \"atools.shapeSizeFractionalDiff.prep.selectors.snSelector.threshold\"\n",
    "pipeline.addConfigOverride(\"analyzeObjectTableCore\", configKey, 400)\n",
    "\n",
    "bands = ['g', 'r', 'i', 'z']\n",
    "pipeline.addConfigOverride(\"analyzeObjectTableCore\", \"bands\", bands)\n",
    "pipeline.addConfigOverride(\"catalogMatchTract\", \"bands\", bands)\n",
    "pipeline.addConfigOverride(\"refCatObjectTract\", \"bands\", bands)\n",
    "\n",
    "# restrict processing to the same dataId used above\n",
    "whereString = \"tract = 9813 AND skymap = 'hsc_rings_v1'\"\n",
    "\n",
    "# Prevent the executor from dumping plots into the notebook\n",
    "backend_ =  mpl.get_backend() \n",
    "mpl.use(\"Agg\")\n",
    "\n",
    "executor = SimplePipelineExecutor.from_pipeline(pipeline, where=whereString, butler=butlerRW)\n",
    "quanta = executor.run(True)\n",
    "\n",
    "# Restore the ability for plots to be put into the notebook\n",
    "mpl.use(backend_)\n",
    "\n",
    "# If you only want to run one plot in a task in the pipeline do the following prior to execution\n",
    "# pipeline.addConfigOverride(\"analyzeObjectTableCore\", \"plots\", None)\n",
    "# pipeline.addConfigOverride(\"analyzeObjectTableCore\", \"plots\", ShapeSizeFractionalDiffScatterPlot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c9a863-4bac-49d4-bd1b-e29529cabafc",
   "metadata": {},
   "source": [
    "### Inspect the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c705181",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# refresh our read-only butler to see the changes made. (it's generally a\n",
    "# good idea to work on read-only things)\n",
    "butler.registry.refresh()\n",
    "\n",
    "# see what datasets exist; there should now be objectTableCore_metrics\n",
    "# for d in sorted(butler.registry.queryDatasetTypes()): print(d.name)\n",
    "\n",
    "# get the metric that was written\n",
    "refs = sorted(butler.registry.queryDatasets(\"objectTableCore_metrics\", collections=outputCollection))\n",
    "refs[0].dataId\n",
    "objectTable_metrics = butler.get(\"objectTableCore_metrics\", dataId=refs[0].dataId, collections=outputCollection)\n",
    "pprint(objectTable_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5721b9f-42e5-4be2-bd8d-9452681faa0c",
   "metadata": {},
   "source": [
    "### Reconstruct the inputs to an analysis_tool\n",
    "\n",
    "Analysis(Tools/Actions) allow the exact state of and AnalysisTools to be saved into the butler when a pipeline is run. This allows a user to 'reconstruct' things as they were when the tools were executed. This aids in debugging and deep diving into the data.\n",
    "\n",
    "Below is an example of reconstructing one of the tasks that was run in the Pipeline above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a60b9b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lsst.analysis.tools.tasks.reconstructor import reconstructAnalysisTools\n",
    "\n",
    "# Read in just one task\n",
    "label = \"analyzeObjectTableCore\"\n",
    "taskState, inputData = reconstructAnalysisTools(butler, collection=outputCollection, label=label, dataId=dataId, callback=None)\n",
    "pprint(taskState)\n",
    "pprint(inputData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecfe9f3-9cc7-4066-9c93-3a149685ba22",
   "metadata": {},
   "source": [
    "Notice that we have access to the object table used to produce the diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b66588-7aef-40e4-a658-9c826d0dae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9cb025-ee6e-4d55-a0fd-fdd1c6153c54",
   "metadata": {},
   "source": [
    "We can now reproduce diagnostic plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf26785-9373-4448-a81d-4f21e934734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following configuration won't be needed in the future\n",
    "taskState.plots.shapeSizeFractionalDiffScatter.produce.addSummaryPlot = False\n",
    "\n",
    "# Rerun one of the plots\n",
    "taskState.plots.shapeSizeFractionalDiffScatter(\n",
    "    inputData['data'],\n",
    "    band='i',\n",
    "    skymap=None,\n",
    "    plotInfo=_StandinPlotInfo()\n",
    ")\n",
    "\n",
    "# change some configuration to see the differences\n",
    "taskState.plots.shapeSizeFractionalDiffScatter.prep.selectors.snSelector.threshold = 50\n",
    "taskState.plots.shapeSizeFractionalDiffScatter(\n",
    "    inputData['data'],\n",
    "    band='i',\n",
    "    skymap=None,\n",
    "    plotInfo=_StandinPlotInfo()\n",
    ")\n",
    "\n",
    "# This could be run in stages like the above example to investigate issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf56cde4-0c53-42ad-9e7f-374f58a0b27d",
   "metadata": {},
   "source": [
    "## Make a custom analysis tool\n",
    "\n",
    "Let's take a look at what at how a metric is implemented before creating a new AnalysisTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b78d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is copied from lsst.analysis.tools.analysisMetrics.limitingMagnitudeMetric\n",
    "\n",
    "from lsst.analysis.tools.interfaces import AnalysisMetric\n",
    "\n",
    "class FiveSigmaPointSourceDepthMetric(AnalysisMetric):\n",
    "    \"\"\"Calculate the five-sigma point source depth of a visit, based on the\n",
    "    PSF flux and its reported error. By default the calculation selects\n",
    "    objects between 4.75 < S/N < 5.25, but these limits are configurable.\n",
    "    The flux type to use for selection is also configurable. Both the median\n",
    "    and mean 5-sigma depths are returned.\n",
    "    \"\"\"\n",
    "\n",
    "    parameterizedBand: bool = False\n",
    "\n",
    "    def setDefaults(self):\n",
    "        super().setDefaults()\n",
    "\n",
    "        self.prep.selectors.starSelector = StarSelector()\n",
    "        self.prep.selectors.starSelector.columnKey = \"extendedness\"\n",
    "\n",
    "        self.prep.selectors.snSelector = SnSelector()\n",
    "        self.prep.selectors.snSelector.fluxType = \"psfFlux\"\n",
    "        # Select between 4.75 < SNR < 5.25 to get a decent sample:\n",
    "        self.prep.selectors.snSelector.threshold = 4.75\n",
    "        self.prep.selectors.snSelector.maxSN = 5.25\n",
    "\n",
    "        self.process.buildActions.mags = ConvertFluxToMag(vectorKey=\"psfFlux\")\n",
    "        self.process.calculateActions.median5sigmaDepth = MedianAction(vectorKey=\"mags\")\n",
    "        self.process.calculateActions.mean5sigmaDepth = MeanAction(vectorKey=\"mags\")\n",
    "\n",
    "        self.produce.units = {\n",
    "            \"median5sigmaDepth\": \"mag\",\n",
    "            \"mean5sigmaDepth\": \"mag\",\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba839c5",
   "metadata": {},
   "source": [
    "As discussed above, AnalysisTools (AnalysisMetric is a specialized subclass) are container classes for AnalysisActions.\n",
    "\n",
    "To make deploying metrics and plots as easy as possible Analysis(Metric/Plots) contain default AnalysisActions that enable new AnalysisTools to be created by simply setting configuration.\n",
    "\n",
    "The default prep action allow specifiying keys to load from input data, and applying selectors. If calling an AnalysisTool directly, the required keys can be set automatically.\n",
    "\n",
    "The default process action itself has 3 stages to it,\n",
    "* buildActions - actions which build derived data\n",
    "* filterActions - If derived data needs to be filtered it can go here\n",
    "* calculateActions - Any final calculations that may need done can be put here\n",
    "\n",
    "These stages run sequentually, and any stage are allowed to have no actions set to run in them.\n",
    "\n",
    "AnalysisMetrics have a default action which allow values produced in process to be mapped to lsst.verify.Measurements\n",
    "\n",
    "The produce stage of AnalysisPlots do not have a default, as this is where the plot to produce is to be set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ca7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.analysis.tools.actions.scalar import MedianAction\n",
    "from lsst.analysis.tools.actions.vector import SnSelector\n",
    "\n",
    "class DemoMetric(AnalysisMetric):\n",
    "    def setDefaults(self):\n",
    "        super().setDefaults()\n",
    "        \n",
    "        # select on high signal to noise obejcts\n",
    "        # add in a signal to noise selector\n",
    "        self.prep.selectors.snSelector = SnSelector()\n",
    "        \n",
    "        # set what key the selector should use when deciding SNR\n",
    "        self.prep.selectors.snSelector.fluxType = \"psfFlux\"\n",
    "        \n",
    "        # select what threshold value is desireable for the selector\n",
    "        self.prep.selectors.snSelector.threshold = 100\n",
    "        \n",
    "        # the final name in the qualification is used as a key to insert\n",
    "        # the calculation into KeyedData\n",
    "        self.process.calculateActions.medianValueName = MedianAction(vectorKey=\"psfFlux\")\n",
    "        \n",
    "        # tell the metic what the units are for the quantity\n",
    "        self.produce.units = {\"medianValueName\": \"Jy\"}\n",
    "        \n",
    "        # Rename the quanity prior to producing the Metric\n",
    "        # (useful for resuable workflows that set a name toward the end of computation)\n",
    "        self.produce.newNames = {\"medianValueName\": \"DemoMetric\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47523e0b-b5cb-4907-ae09-0929fbf7492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some fake data\n",
    "fluxes = np.random.normal(100000, 100, 500)\n",
    "data = {\"psfFlux\": fluxes, \"psfFluxErr\": np.sqrt(fluxes)}\n",
    "metric = DemoMetric()(data)\n",
    "metric"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
